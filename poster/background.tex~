\section{Background}
\label{sec:background}

Collaborative-filtering is a recommendation approach that uses similarity between users and the benefit they have received from items in the past to make recommendations. Three main approaches to collaborative filtering are memory-based, model-based and hybrid methods~\cite{Su:2009:SCF:1592474.1722966} . Memory-based approaches, specifically item-based recommender~\ref{fig:predict}, use an item-user rating matrix to compute pairwise similarities between items. In the contexts of courses, enrollment roster, previous courses students taken and grades course give, is a natural way to reason about course similarity.  

\begin{figure}[h]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=\linewidth]{figs/predict}
 \caption{Typical student course grade table}
 \label{fig:predict}
\end{figure}

However the recommendation approaches are not appropriate for our problems, since they are used for making predictions which means, the approach is designed to fill in the missing values in the matrix. For our case, however, we want to figure out how two courses are correlated with each other. We don’t want to fill the matrix since it will blur the original data. What’ more, for each two courses we are only interested in the users who take both of them. Visualization is an effective and intuitive way to approach our goal.  

There’re many existing similarity measures to compare two entities. Well known metrics include Euclidean similarity, Jaccard(Tanimoto) similarity, Pearson Correlation Coefficient, cosine similarity and Log-likelihood similarity etc. Euclidean similarity measures the distance between courses grading vectors. Jaccard(Tanimoto) similarity is calculated by dividing the intersection of the sets by the union of those sets\cite{sandvig2005aacorn}. Cosine Similarity envision user’s ratings as points in space and measures the cosine of the angle between these lines drawn from origin to each point. The Log-likelihood similarity is a measure of how often items from 2 sets appear together versus how often they appear apart. Pearson Correlation Coefficient is a number between -1, 1. It measures the tendency of the rating vectors, paired one by one, and it’s typically used in early research papers. It formula is given as $pearson-correlation(u,w) = \frac{cov(R_u,R_w)}{\sigma x \sigma y} $ where $cov$ stands for covariance and $\sigma x$ stands for standard deviation of $x$. We are interested in the strong positive correlation and the positive correlation as illustrated in~\ref{fig:psc}.

For our work, Euclidean similarity is not suitable because courses taken by more students will be added more distances. Jaccard(Tanimoto) similarity and Log-likelihood don’t count grades students get. We choose Pearson Correlation coefficient to indicate the similarity between two records. 
\begin{figure}[h]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=1.5in]{figs/psc_illustrated}
\caption{Pearson Correlation Illustrated}
 \label{fig:psc}
\end{figure}
\subsection{Related Work}
\label{sec:related}

The problem of coursework similarity has been studied in the context of course recommendation system. Bendakir et al.~\cite{bendakir2006using} proposed a recommendation system based on decision tree of course history. Their approach, however, does not consider students' grades at all. Thus, their tool may wrongly correlate totally different courses simply due to historical mistakes. Sandvig et al.~\cite{sandvig2005aacorn} did use the GPA information, but GPA, as an average metric, doesn't say much about each specific class. 

When it comes to the visualization problem. Since our goal is to cluster similar classes together, a node-link diagram naturally jumps into our mind. D3 library has a force-directed graph that is close to our needs. But we are hesitant about its fisheye distortion and curved link variant because these variants make it hard to click on nodes or edges for further details. We are also aware that force directed drawing is criticized for local minima. A multilevel approach~\cite{walshaw2000multilevel} might fix it but we are not focusing on algorithmic style improvement in this proposal.

Other well-known techniques include Rheingold-Tilford Tree, whose tree hierarchy is too constrained to express clustered nodes; arc diagram, whose purpose is to highlight existing cycles. We investigate but decide not to use them. 

